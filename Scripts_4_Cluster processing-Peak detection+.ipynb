{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sin,isnan\n",
    "from pylab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:/mins15_final_data-11839.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Unnamed: 0'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"Cluster_wise_meters.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = df2[df2['clus_num'] == 1]\n",
    "c2 = df2[df2['clus_num'] == 2]\n",
    "c3 = df2[df2['clus_num'] == 3]\n",
    "c4 = df2[df2['clus_num'] == 4]\n",
    "c5 = df2[df2['clus_num'] == 5]\n",
    "c6 = df2[df2['clus_num'] == 6]\n",
    "c7 = df2[df2['clus_num'] == 7]\n",
    "c8 = df2[df2['clus_num'] == 8]\n",
    "c9 = df2[df2['clus_num'] == 9]\n",
    "c10 = df2[df2['clus_num'] == 10]\n",
    "c11 = df2[df2['clus_num'] == 11]\n",
    "c12 = df2[df2['clus_num'] == 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read all csv meters files\n",
    "for index, row in c12.iterrows():\n",
    "    no = row['idmeter']#.astype(str)\n",
    "    df3 = df[df['idmeter'].str.contains(no+'$', regex=True)]\n",
    "    df3.to_csv(\"ClusterCSV_data/Cluster 12/Cluster12_\"+no+\"_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = pd.DataFrame(columns=['idmeter', 'Average_load(KWh)', 'Morn_Peak_avarge_load(KWh)', 'Eve_Peak_avarge_load(KWh)','Peak_mor_7_10','Peak_eve_17_23','Total_peaks', 'Solar_size',\n",
    "                           'Demand7to18day', 'Totaldemandday', 'Eligible_DSM','Eligible_NM','Eligible_DSM_NM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak1 = 0\n",
    "peak2 = 0\n",
    "eligible_dsm = 0\n",
    "eligible_nm = 0\n",
    "eligible_dsm_nm = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in c12.iterrows():\n",
    "    no = row['idmeter']\n",
    "    df5 = pd.read_csv(\"ClusterCSV_data/Cluster 12/Cluster12_\"+no+\"_data.csv\")\n",
    "    df5.set_index('idmeter')\n",
    "    df5['Average'] = df5.mean(axis=1)\n",
    "    Average_load = (df5['Average'].mean(axis=0)) * 4\n",
    "    Average_load_peaks = Average_load * 1.7\n",
    "    df5['Eve_Peak Average'] = df5.iloc[:, [70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93]].mean(axis=1)\n",
    "    Eve_Peak_average_load = (df5['Eve_Peak Average'].mean(axis=0)) * 4\n",
    "    df5['Morn_Peak Average'] = df5.loc[:, '07:00':'09:45'].mean(axis=1)\n",
    "    Morn_Peak_average_load = (df5['Morn_Peak Average'].mean(axis=0)) * 4\n",
    "    #df5['Total_usage'] = df5.iloc[:, [30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74]].sum(axis=1)\n",
    "    #Total_usage = (df5['Total_usage'].mean(axis=0))\n",
    "    #To find the number of peaks - starts\n",
    "    df5['peak_7_8'] = df5.loc[:, '07:00':'07:45'].sum(axis=1)\n",
    "    peak_7_8 = (df5['peak_7_8'].mean(axis=0))\n",
    "    df5['peak_8_9'] = df5.loc[:, '08:00':'08:45'].sum(axis=1)\n",
    "    peak_8_9 = (df5['peak_8_9'].mean(axis=0))\n",
    "    df5['peak_9_10'] = df5.loc[:, '09:00':'09:45'].sum(axis=1)\n",
    "    peak_9_10 = (df5['peak_9_10'].mean(axis=0))\n",
    "    df5['peak_17_18'] = df5.loc[:, '17:00':'17:45'].sum(axis=1)\n",
    "    peak_17_18 = (df5['peak_17_18'].mean(axis=0))\n",
    "    df5['peak_18_19'] = df5.loc[:, '18:00':'18:45'].sum(axis=1)\n",
    "    peak_18_19 = (df5['peak_18_19'].mean(axis=0))\n",
    "    df5['peak_19_20'] = df5.loc[:, '19:00':'19:45'].sum(axis=1)\n",
    "    peak_19_20 = (df5['peak_19_20'].mean(axis=0))\n",
    "    df5['peak_20_21'] = df5.loc[:, '20:00':'20:45'].sum(axis=1)\n",
    "    peak_20_21 = (df5['peak_20_21'].mean(axis=0))\n",
    "    df5['peak_21_22'] = df5.loc[:, '21:00':'21:45'].sum(axis=1)\n",
    "    peak_21_22 = (df5['peak_21_22'].mean(axis=0))\n",
    "    df5['peak_22_23'] = df5.loc[:, '22:00':'22:45'].sum(axis=1)\n",
    "    peak_22_23 = (df5['peak_22_23'].mean(axis=0))\n",
    "    if peak_7_8 > Average_load_peaks or peak_8_9 > Average_load_peaks or peak_9_10 > Average_load_peaks:\n",
    "        peak1 = peak1 + 1\n",
    "    if peak_17_18 > Average_load_peaks or peak_18_19 > Average_load_peaks or peak_19_20 > Average_load_peaks or peak_20_21 > Average_load_peaks or peak_21_22 > Average_load_peaks or peak_22_23 > Average_load_peaks:\n",
    "        peak2 = peak2 + 1\n",
    "    total_peaks = peak1+peak2\n",
    "    #To find the number of peaks- ends\n",
    "    #Find solar panel size - starts \n",
    "    Size_solar = ((df5.loc[:, '00:00':'23:45'].sum().sum())*0.9)/(0.1820 * 2952)\n",
    "    #Find solar panel size - ends\n",
    "    #Find the proportion of 7 to 6 (inclusive) demand in a day - starts\n",
    "    totaldemandday = df5.loc[:,'00:00':'23:45'].mean().sum()\n",
    "    #totaldemandday = df5['7to6demand'].sum()\n",
    "    demand7to18day = df5.loc[:, '07:00':'18:00'].mean().sum()\n",
    "    consump_7_18 = (demand7to18day/totaldemandday) * 100\n",
    "    #Find the proportion of 7 to 6 (inclusive) demand in a day - ends\n",
    "    if total_peaks >= 1:\n",
    "        eligible_dsm = eligible_dsm + 1\n",
    "    if consump_7_18 > 50 and Size_solar >= 1:\n",
    "        eligible_nm = eligible_nm + 1\n",
    "    if total_peaks >= 1 and consump_7_18 > 50 and Size_solar >= 1:\n",
    "        eligible_dsm_nm = eligible_dsm_nm + 1\n",
    "    df6 = df6.append({'idmeter': no, 'Average_load(KWh)': Average_load, 'Morn_Peak_avarge_load(KWh)': Morn_Peak_average_load, 'Eve_Peak_avarge_load(KWh)': Eve_Peak_average_load, 'Peak_mor_7_10': peak1, \n",
    "                      'Peak_eve_17_23': peak2,'Total_peaks': total_peaks, 'Solar_size': Size_solar, 'Demand7to18day': demand7to18day, 'Totaldemandday': totaldemandday,\n",
    "                      'Eligible_DSM': eligible_dsm,'Eligible_NM': eligible_nm,'Eligible_DSM_NM': eligible_dsm_nm}, ignore_index=True)\n",
    "    peak1 = 0\n",
    "    peak2 = 0\n",
    "    eligible_dsm = 0\n",
    "    eligible_nm = 0\n",
    "    eligible_dsm_nm = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6.insert(loc=3, column='Morn_difference', value=df6['Morn_Peak_avarge_load(KWh)'] - df6['Average_load(KWh)'])\n",
    "df6.insert(loc=5, column='Eve_difference', value=df6['Eve_Peak_avarge_load(KWh)'] - df6['Average_load(KWh)'])\n",
    "df6['ConsumptionPerc7to18'] = (df6['Demand7to18day']/df6['Totaldemandday'])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6.to_csv(\"Cluster_results/Cluster12_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame(columns=['Cluster No', 'Morn_Perc_peak>avg', 'Eve_Perc_peak>avg', 'Peak_morn_7_10','Peak_eve_17_23', 'Total_peaks_0', \n",
    "                             'Total_peaks_1', 'Total_peaks_2', 'Solar size>=1', 'Proportion7to18Consu>60','EligibleDSM','EligibleNM','EligibleDSM_NM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Cluster_statistics/Cluster1_statistics.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-f36d408c1b9f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mdf_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cluster_statistics/Cluster\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"_statistics.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;31m#df_2 = pd.read_csv(\"ClusterCSV_data/Cluster_statistics/Cluster1_statistics.csv\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     df_1 = df_1.append({'Cluster No': i, 'Morn_Perc_peak>avg': len(df_2.loc[df_2.Morn_difference > 0])*100 / df_2['idmeter'].nunique(),\n\u001b[0;32m      5\u001b[0m                     \u001b[1;34m'Eve_Perc_peak>avg'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEve_difference\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mdf_2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'idmeter'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnunique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    934\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 936\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    937\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    938\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1166\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1167\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1168\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1169\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1170\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1996\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1997\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1998\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1999\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Cluster_statistics/Cluster1_statistics.csv'"
     ]
    }
   ],
   "source": [
    "for i in range(1,13):\n",
    "    df_2 = pd.read_csv(\"Cluster_results/Cluster\"+str(i)+\"_statistics.csv\")\n",
    "    #df_2 = pd.read_csv(\"ClusterCSV_data/Cluster_statistics/Cluster1_statistics.csv\")\n",
    "    df_1 = df_1.append({'Cluster No': i, 'Morn_Perc_peak>avg': len(df_2.loc[df_2.Morn_difference > 0])*100 / df_2['idmeter'].nunique(),\n",
    "                    'Eve_Perc_peak>avg': len(df_2.loc[df_2.Eve_difference > 0])*100 / df_2['idmeter'].nunique(),\n",
    "                    'Peak_morn_7_10': len(df_2.loc[df_2.Peak_mor_7_10 == 1])*100 / df_2['idmeter'].nunique(),\n",
    "                    'Peak_eve_17_23': len(df_2.loc[df_2.Peak_eve_17_23 == 1])*100 / df_2['idmeter'].nunique(),\n",
    "                    'Total_peaks_0': len(df_2.loc[df_2.Total_peaks == 0])*100 / df_2['idmeter'].nunique(),\n",
    "                    'Total_peaks_1': len(df_2.loc[df_2.Total_peaks == 1])*100 / df_2['idmeter'].nunique(),\n",
    "                    'Total_peaks_2': len(df_2.loc[df_2.Total_peaks == 2])*100 / df_2['idmeter'].nunique(),\n",
    "                    'Solar size>=1': (len(df_2.loc[df_2['Solar_size'] >= 1]))*100 / df_2['idmeter'].nunique(),\n",
    "                    'Proportion7to18Consu>60':(len(df_2.loc[df_2['ConsumptionPerc7to18'] > 50]))*100 / df_2['idmeter'].nunique(),\n",
    "                    'EligibleDSM': len(df_2.loc[df_2.Eligible_DSM == 1])*100 / df_2['idmeter'].nunique(),\n",
    "                    'EligibleNM': len(df_2.loc[df_2.Eligible_NM == 1])*100 / df_2['idmeter'].nunique(),\n",
    "                    'EligibleDSM_NM': len(df_2.loc[df_2.Eligible_DSM_NM == 1])*100 / df_2['idmeter'].nunique(),}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.to_csv(\"Cluster_results/All_clusters_results.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
